{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d457edf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(r\"C:\\Users\\ulloa-to\\git\\Advanced_Remote_sensing_HM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f1a2a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to all input and output data folders\n",
    "geotiff_path = \"data/s2_change_rasters/\"\n",
    "vector_path = \"data/vector/\"\n",
    "output_path = \"data/wk4_results/\"\n",
    "\n",
    "# paths to all input files\n",
    "geotiff = os.path.join(geotiff_path, \"july_32N_subset.tif\")\n",
    "truth_shp = os.path.join(vector_path, \"wk4_truth.shp\")\n",
    "train_shp = os.path.join(vector_path, \"wk4_train.shp\")\n",
    "test_shp = os.path.join(vector_path, \"wk4_test.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a6ca922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/s2_change_rasters/july_32N_subset.tif'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34834a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to all output files\n",
    "segmented_geotiff = os.path.join(output_path, \"wk4_segmented_raster.tif\") # intermediate result. Not the final classification\n",
    "class_tif = os.path.join(output_path, \"wk4_classified.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "086be218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory, where our logfile is saved:\n",
    "log_txt = os.path.join(output_path, 'wk4_log.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b41c3318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input raster has:  4 bands 306 rows 547 columns\n"
     ]
    }
   ],
   "source": [
    "import gdal\n",
    "\n",
    "# read raster\n",
    "driverTiff = gdal.GetDriverByName(\"GTiff\")\n",
    "geotiff_ds = gdal.Open(geotiff) # open my geotiff. Input is the path where my geotiff is located\n",
    "nbands = geotiff_ds.RasterCount\n",
    "\n",
    "print(\"Input raster has: \", nbands, \"bands\", \n",
    "     geotiff_ds.RasterYSize, \"rows\", \n",
    "     geotiff_ds.RasterXSize, \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4b1b101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a0614f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the band data \n",
    "\n",
    "band_data = []\n",
    "\n",
    "for i in range(1, nbands):\n",
    "    band = geotiff_ds.GetRasterBand(i).ReadAsArray()\n",
    "    band_data.append(band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a3b5789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[141.97078 , 120.89179 , 117.206055, ..., 241.006   , 247.377   ,\n",
       "         256.05417 ],\n",
       "        [132.29724 , 113.83605 , 118.945595, ..., 244.6418  , 264.463   ,\n",
       "         234.0646  ],\n",
       "        [178.26851 , 149.32114 , 133.75113 , ..., 256.55307 , 257.09695 ,\n",
       "         251.8949  ],\n",
       "        ...,\n",
       "        [216.41963 , 199.07092 , 189.93814 , ..., 365.6931  , 280.34537 ,\n",
       "         231.03635 ],\n",
       "        [186.23952 , 199.40797 , 205.52094 , ..., 283.01288 , 273.86563 ,\n",
       "         263.60315 ],\n",
       "        [204.12527 , 213.6489  , 208.99358 , ..., 231.86484 , 224.74828 ,\n",
       "         246.62582 ]], dtype=float32),\n",
       " array([[252.05565, 204.0534 , 227.46196, ..., 431.0481 , 438.10355,\n",
       "         477.33298],\n",
       "        [244.4107 , 218.902  , 229.48067, ..., 447.6187 , 436.9584 ,\n",
       "         420.22748],\n",
       "        [320.9689 , 266.39667, 258.47968, ..., 472.05646, 435.234  ,\n",
       "         446.34195],\n",
       "        ...,\n",
       "        [381.70718, 344.18674, 342.47073, ..., 548.48334, 462.7615 ,\n",
       "         407.23816],\n",
       "        [329.3405 , 344.52206, 363.75974, ..., 440.21466, 459.61823,\n",
       "         459.96707],\n",
       "        [342.94482, 361.4851 , 368.27817, ..., 344.8592 , 381.00186,\n",
       "         449.11716]], dtype=float32),\n",
       " array([[146.9026  , 119.38423 , 123.606125, ..., 255.98997 , 259.5902  ,\n",
       "         291.56863 ],\n",
       "        [142.13403 , 131.14621 , 125.00334 , ..., 255.58315 , 279.26172 ,\n",
       "         253.54315 ],\n",
       "        [218.33928 , 158.51265 , 147.24445 , ..., 261.80576 , 253.31839 ,\n",
       "         249.4019  ],\n",
       "        ...,\n",
       "        [208.07506 , 194.35475 , 190.35431 , ..., 519.47437 , 353.39453 ,\n",
       "         253.95255 ],\n",
       "        [192.3588  , 199.54921 , 203.08875 , ..., 338.78403 , 336.13098 ,\n",
       "         309.7173  ],\n",
       "        [197.31624 , 207.31105 , 208.13458 , ..., 222.43422 , 249.56757 ,\n",
       "         291.16992 ]], dtype=float32)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "band_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdfde96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[141.97078 , 120.89179 , 117.206055, ..., 241.006   ,\n",
       "         247.377   , 256.05417 ],\n",
       "        [132.29724 , 113.83605 , 118.945595, ..., 244.6418  ,\n",
       "         264.463   , 234.0646  ],\n",
       "        [178.26851 , 149.32114 , 133.75113 , ..., 256.55307 ,\n",
       "         257.09695 , 251.8949  ],\n",
       "        ...,\n",
       "        [216.41963 , 199.07092 , 189.93814 , ..., 365.6931  ,\n",
       "         280.34537 , 231.03635 ],\n",
       "        [186.23952 , 199.40797 , 205.52094 , ..., 283.01288 ,\n",
       "         273.86563 , 263.60315 ],\n",
       "        [204.12527 , 213.6489  , 208.99358 , ..., 231.86484 ,\n",
       "         224.74828 , 246.62582 ]],\n",
       "\n",
       "       [[252.05565 , 204.0534  , 227.46196 , ..., 431.0481  ,\n",
       "         438.10355 , 477.33298 ],\n",
       "        [244.4107  , 218.902   , 229.48067 , ..., 447.6187  ,\n",
       "         436.9584  , 420.22748 ],\n",
       "        [320.9689  , 266.39667 , 258.47968 , ..., 472.05646 ,\n",
       "         435.234   , 446.34195 ],\n",
       "        ...,\n",
       "        [381.70718 , 344.18674 , 342.47073 , ..., 548.48334 ,\n",
       "         462.7615  , 407.23816 ],\n",
       "        [329.3405  , 344.52206 , 363.75974 , ..., 440.21466 ,\n",
       "         459.61823 , 459.96707 ],\n",
       "        [342.94482 , 361.4851  , 368.27817 , ..., 344.8592  ,\n",
       "         381.00186 , 449.11716 ]],\n",
       "\n",
       "       [[146.9026  , 119.38423 , 123.606125, ..., 255.98997 ,\n",
       "         259.5902  , 291.56863 ],\n",
       "        [142.13403 , 131.14621 , 125.00334 , ..., 255.58315 ,\n",
       "         279.26172 , 253.54315 ],\n",
       "        [218.33928 , 158.51265 , 147.24445 , ..., 261.80576 ,\n",
       "         253.31839 , 249.4019  ],\n",
       "        ...,\n",
       "        [208.07506 , 194.35475 , 190.35431 , ..., 519.47437 ,\n",
       "         353.39453 , 253.95255 ],\n",
       "        [192.3588  , 199.54921 , 203.08875 , ..., 338.78403 ,\n",
       "         336.13098 , 309.7173  ],\n",
       "        [197.31624 , 207.31105 , 208.13458 , ..., 222.43422 ,\n",
       "         249.56757 , 291.16992 ]]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# read your band\n",
    "band_data = np.stack(band_data)\n",
    "band_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dff18935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.01139604, 0.00917078, 0.00878168, ..., 0.02185098,\n",
       "         0.02252355, 0.02343958],\n",
       "        [0.01037483, 0.00842592, 0.00896532, ..., 0.0222348 ,\n",
       "         0.02432729, 0.02111819],\n",
       "        [0.01522792, 0.012172  , 0.01052831, ..., 0.02349225,\n",
       "         0.02354967, 0.0230005 ],\n",
       "        ...,\n",
       "        [0.01925545, 0.01742398, 0.01645985, ..., 0.03501394,\n",
       "         0.02600395, 0.0207985 ],\n",
       "        [0.0160694 , 0.01745956, 0.0181049 , ..., 0.02628556,\n",
       "         0.0253199 , 0.02423651],\n",
       "        [0.01795756, 0.01896295, 0.0184715 , ..., 0.02088597,\n",
       "         0.02013469, 0.02244425]],\n",
       "\n",
       "       [[0.02301747, 0.01794997, 0.02042116, ..., 0.04191332,\n",
       "         0.04265815, 0.04679952],\n",
       "        [0.02221041, 0.01951751, 0.02063427, ..., 0.04366265,\n",
       "         0.04253726, 0.04077101],\n",
       "        [0.0302925 , 0.02453142, 0.02369564, ..., 0.04624249,\n",
       "         0.04235522, 0.04352786],\n",
       "        ...,\n",
       "        [0.03670451, 0.03274355, 0.0325624 , ..., 0.05431071,\n",
       "         0.04526124, 0.03939976],\n",
       "        [0.03117627, 0.03277895, 0.03480983, ..., 0.04288102,\n",
       "         0.04492941, 0.04496624],\n",
       "        [0.03261245, 0.03456971, 0.03528684, ..., 0.03281454,\n",
       "         0.03663005, 0.04382084]],\n",
       "\n",
       "       [[0.01191668, 0.00901163, 0.00945732, ..., 0.02343281,\n",
       "         0.02381288, 0.02718877],\n",
       "        [0.01141328, 0.01025331, 0.00960482, ..., 0.02338986,\n",
       "         0.02588955, 0.0231745 ],\n",
       "        [0.0194581 , 0.01314233, 0.01195277, ..., 0.02404677,\n",
       "         0.02315077, 0.02273732],\n",
       "        ...,\n",
       "        [0.01837453, 0.01692611, 0.01650379, ..., 0.0512483 ,\n",
       "         0.0337156 , 0.02321772],\n",
       "        [0.0167154 , 0.01747447, 0.01784814, ..., 0.0321732 ,\n",
       "         0.03189312, 0.02910469],\n",
       "        [0.01723874, 0.01829388, 0.01838081, ..., 0.0198904 ,\n",
       "         0.02275481, 0.02714668]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage import exposure\n",
    "\n",
    "img = exposure.rescale_intensity(band_data)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff49153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "print(\"start time of processing:\", now.strftime(\"%Y-%m-%d %H:%M:%S\"), file = open(log_txt, \"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee751efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLIC segmentation algorithm\n",
    "n_segments_var = 15000 #try: 10000, 5000, 20000\n",
    "compactness_var = 0.5 #0.001, 0.1, 1 \n",
    "max_iter_var = 10 #50, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76028d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import slic\n",
    "\n",
    "# segmentation\n",
    "\n",
    "# maybe don't write the function like this\n",
    "# skimage.segmentation.slic(img, compactness_var, n_segments_var, max_iter_var)\n",
    "\n",
    "# write the function in an explicit way\n",
    "segments = slic(img, n_segments = n_segments_var,\n",
    "                compactness = compactness_var, max_iter = max_iter_var, start_label=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dd3e3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ulloa-to\\Anaconda3\\envs\\rio\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3622: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      "C:\\Users\\ulloa-to\\Anaconda3\\envs\\rio\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# let's add metrics to every segment\n",
    "\n",
    "import scipy\n",
    "\n",
    "def segment_features(segment_pixels):\n",
    "    features = []\n",
    "    npixels, nbands = segment_pixels.shape\n",
    "    for b in range(nbands):\n",
    "        stats = scipy.stats.describe(segment_pixels[:, b])\n",
    "        band_stats = list(stats.minmax) + list(stats)[2:]\n",
    "        if npixels == 1:\n",
    "            band_stats[3] = 0.0\n",
    "        features += band_stats\n",
    "    return features\n",
    "\n",
    "# extract stats from every segment of my raster\n",
    "segment_ids = np.unique(segments)\n",
    "objects = []\n",
    "objects_ids = []\n",
    "\n",
    "for id in segment_ids:\n",
    "    segment_pixels = img[segments == id]\n",
    "    object_features = segment_features(segment_pixels)\n",
    "    objects.append(object_features)\n",
    "    objects_ids.append(id)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "289010bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rasterize the segments (or export them)\n",
    "\n",
    "# save segments to raster\n",
    "output_fullpath = segmented_geotiff # where I want to save my segmented raster\n",
    "segments_ds = driverTiff.Create(output_fullpath, geotiff_ds.RasterXSize,\n",
    "                                geotiff_ds.RasterYSize, 1, gdal.GDT_Float32)\n",
    "segments_ds.SetGeoTransform(geotiff_ds.GetGeoTransform())\n",
    "segments_ds.SetProjection(geotiff_ds.GetProjectionRef())\n",
    "segments_ds.GetRasterBand(1).WriteArray(segments)\n",
    "segments_ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41cea23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# add the truth data\n",
    "gdf = gpd.read_file(truth_shp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d719ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get info on my class names\n",
    "class_names = gdf[\"label\"].unique()\n",
    "class_names\n",
    "\n",
    "print(\"class names of the truth shp are: \", class_names, file = open(log_txt, \"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83c50586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_ids = np.arange(class_names.size) #### == 0,1,2,3,4  #we dont want this\n",
    "class_ids = np.arange(class_names.size) + 1 ### == 1,2,3,4,5\n",
    "\n",
    "print(\"class_ids of my truth shp are:\", class_ids, file = open(log_txt, \"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74a4de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the truth data into train 70% and test 30%\n",
    "\n",
    "gdf_train = gdf.sample(frac = 0.7)\n",
    "gdf_test = gdf.drop(gdf_train.index)\n",
    "\n",
    "print(\"truth data shape:\", gdf.shape, \n",
    "     \"train data shape:\", gdf_train.shape,\n",
    "     \"test data shape:\", gdf_test.shape, file = open(log_txt, \"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a60c4d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export your test and train as shp\n",
    "gdf_train.to_file(train_shp)\n",
    "gdf_test.to_file(test_shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf88836c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from osgeo import ogr\n",
    "\n",
    "train_fn = train_shp # path of the train.shp\n",
    "train_ds = ogr.Open(train_fn) # open your shp\n",
    "lyr = train_ds.GetLayer() # extract the layer\n",
    "\n",
    "\n",
    "# create a raster container to store the information of our train.shp\n",
    "driver = gdal.GetDriverByName('MEM') #do not store as physical file (geotiff), but keep it in memory\n",
    "target_ds = driver.Create('', geotiff_ds.RasterXSize, geotiff_ds.RasterYSize, 1, gdal.GDT_UInt16)\n",
    "target_ds.SetGeoTransform(geotiff_ds.GetGeoTransform())\n",
    "target_ds.SetProjection(geotiff_ds.GetProjection())\n",
    "\n",
    "# use that raster \"container\" to dump in the info of the train.shp\n",
    "options_shp = [\"ATTRIBUTE=id\"]\n",
    "gdal.RasterizeLayer(target_ds, [1], lyr, options = options_shp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4227bcc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classification\n",
    "\n",
    "# rasterized file in MEM with the training data\n",
    "ground_truth = target_ds.GetRasterBand(1).ReadAsArray\n",
    "classes = np.unique(ground_truth)[1:]\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b3dbfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_per_class = {}\n",
    "for klass in classes: \n",
    "    segments_of_class = segments[ground_truth == klass]\n",
    "    segments_per_class[klass] = set(segments_of_class)\n",
    "    print(\"Training segments for class\", klass, \":\", len(segments_of_class), file=open(log_txt, \"a\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2e06b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = np.copy(segments)\n",
    "threshold = train_img.max() + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c759439",
   "metadata": {},
   "outputs": [],
   "source": [
    "for klass in classes:\n",
    "    class_label = threshold + klass\n",
    "    for segment_id in segments_per_class[klass]:\n",
    "        train_img[train_img == segment_id] = class_label\n",
    "\n",
    "train_img[train_img <= threshold] = 0\n",
    "train_img[train_img > threshold] -= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0295530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_objects = []\n",
    "training_labels = []\n",
    "\n",
    "for klass in classes:\n",
    "    class_train_object = [v for i, v in enumerate(objects) if segment_ids[i] in segments_per_class[klass]]\n",
    "    training_labels += [klass] * len(class_train_object)\n",
    "    training_objects += class_train_object\n",
    "    print('Training objects for class', klass, ':', len(class_train_object), file=open(log_txt, \"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a3aaeda",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-99c9554c0fcf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\rio\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    303\u001b[0m             )\n\u001b[0;32m    304\u001b[0m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[1;32m--> 305\u001b[1;33m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[0m\u001b[0;32m    306\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rio\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rio\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rio\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    819\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 821\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    822\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rio\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rio\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    639\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;31m# make sure we actually converted to numeric:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_jobs = -1)\n",
    "classifier.fit(training_objects, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "005ee0b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-a3db26ad2718>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\rio\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    628\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m--> 630\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rio\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    670\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mterm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \"\"\"\n\u001b[1;32m--> 672\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rio\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rio\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "predicted = classifier.predict(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a9a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply prediction to numpy array\n",
    "clf = np.copy(segments)\n",
    "for segment_id, klass in zip(segment_ids, predicted):\n",
    "    clf[clf == segment_id] = klass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a280d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.sum(img, axis=2)\n",
    "mask[mask > 0.0] = 1.0\n",
    "mask[mask == 0.0] = -1.0\n",
    "clf = np.multiply(clf, mask)\n",
    "clf[clf < 0] = -9999.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ff221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving classification to raster with gdal\n",
    "clfds = driverTiff.Create(class_tif, geotiff_ds.RasterXSize, geotiff_ds.RasterYSize,\n",
    "                          1, gdal.GDT_Float32)\n",
    "clfds.SetGeoTransform(geotiff_ds.GetGeoTransform())\n",
    "clfds.SetProjection(geotiff_ds.GetProjection())\n",
    "clfds.GetRasterBand(1).SetNoDataValue(-9999.0)\n",
    "clfds.GetRasterBand(1).WriteArray(clf) #here I put the classification information into the \"raster container\"\n",
    "clfds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c3d217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load the test data\n",
    "test_fn = test_shp # path\n",
    "test_ds = ogr.Open(test_fn)\n",
    "lyr = test_ds.GetLayer()\n",
    "\n",
    "# create a new raster layer in memory\n",
    "driver = gdal.GetDriverByName('MEM')\n",
    "target_ds = driver.Create('', geotiff_ds.RasterXSize, geotiff_ds.RasterYSize, 1, gdal.GDT_UInt16)\n",
    "target_ds.SetGeoTransform(geotiff_ds.GetGeoTransform())\n",
    "target_ds.SetProjection(geotiff_ds.GetProjection())\n",
    "\n",
    "# rasterize the test points\n",
    "options = ['ATTRIBUTE=id']\n",
    "gdal.RasterizeLayer(target_ds, [1], lyr, options=options)\n",
    "\n",
    "# set test data as truth\n",
    "truth = target_ds.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "# open classified image and set as prediction\n",
    "pred_ds = gdal.Open(class_tif)\n",
    "pred = pred_ds.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "idx = np.nonzero(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f03c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "cm = metrics.confusion_matrix(truth[idx], pred[idx])\n",
    "\n",
    "print(\"Confusion matrix: \",'\\n',cm, file=open(log_txt, \"a\"))\n",
    "\n",
    "print(\"Diagonal: \",cm.diagonal(), file=open(log_txt, \"a\"))\n",
    "print(\"Sum: \",cm.sum(axis=0), file=open(log_txt, \"a\"))\n",
    " \n",
    "accuracy = cm.diagonal() / cm.sum(axis=0)\n",
    "print(\"Accuracy: \",accuracy, file=open(log_txt, \"a\"))\n",
    "\n",
    "\n",
    "# add end datetime to log\n",
    "now = datetime.datetime.now()\n",
    "print (\"### End date and time: \", now.strftime(\"%Y-%m-%d %H:%M:%S\"), file=open(log_txt, \"a\"))\n",
    "\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
