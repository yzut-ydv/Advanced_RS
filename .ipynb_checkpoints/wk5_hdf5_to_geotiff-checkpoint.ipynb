{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0d43d34",
   "metadata": {},
   "source": [
    "# This only works for HDF5 files!\n",
    "## For HDF4 files please consult https://blackmarble.gsfc.nasa.gov/Tools.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f37995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import os\n",
    "from pprint import pprint\n",
    "import re\n",
    "\n",
    "gdal.UseExceptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a00b3c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a list of only hdf files\n",
    "def onlyh5 (files):\n",
    "    newFiles = []\n",
    "    for item in files:\n",
    "        x = re.search(\"\\.h5$\", item)\n",
    "        if x != None:\n",
    "            newFiles.append(item)\n",
    "    return newFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44572e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 HDF5 Files found\n"
     ]
    }
   ],
   "source": [
    "# variables\n",
    "fileExtension = \".tif\"\n",
    "EPSG = \"-a_srs EPSG:4326\" #WGS84\n",
    "\n",
    "# specify folder with hdf files and output folder\n",
    "filepath = \"G:\\\\Documents\\\\_SHK\\\\M5\\\\HDF\\\\\"\n",
    "outputFolder = \"G:\\\\Documents\\\\_SHK\\\\M5\\\\Raster\\\\\"\n",
    "\n",
    "# change working directory to filepath\n",
    "os.chdir(filepath)\n",
    "\n",
    "# create outputFolder if it doesn't exist yet\n",
    "os.makedirs(outputFolder, exist_ok=True)\n",
    "\n",
    "# get list of all hdf files in that folder\n",
    "rasterFiles = os.listdir(os.getcwd())\n",
    "rasterFiles = onlyh5(rasterFiles)\n",
    "print(len(rasterFiles), \"HDF5 Files found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19fa74c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('HDF5:\"VNP46A2.A2020214.h10v04.001.2021076005435.h5\"://HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/DNB_BRDF-Corrected_NTL',\n",
      "  '[2400x2400] //HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/DNB_BRDF-Corrected_NTL '\n",
      "  '(16-bit unsigned integer)'),\n",
      " ('HDF5:\"VNP46A2.A2020214.h10v04.001.2021076005435.h5\"://HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/DNB_Lunar_Irradiance',\n",
      "  '[2400x2400] //HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/DNB_Lunar_Irradiance '\n",
      "  '(16-bit unsigned integer)'),\n",
      " ('HDF5:\"VNP46A2.A2020214.h10v04.001.2021076005435.h5\"://HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/Gap_Filled_DNB_BRDF-Corrected_NTL',\n",
      "  '[2400x2400] '\n",
      "  '//HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/Gap_Filled_DNB_BRDF-Corrected_NTL '\n",
      "  '(16-bit unsigned integer)'),\n",
      " ('HDF5:\"VNP46A2.A2020214.h10v04.001.2021076005435.h5\"://HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/Latest_High_Quality_Retrieval',\n",
      "  '[2400x2400] '\n",
      "  '//HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/Latest_High_Quality_Retrieval '\n",
      "  '(8-bit unsigned character)'),\n",
      " ('HDF5:\"VNP46A2.A2020214.h10v04.001.2021076005435.h5\"://HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/Mandatory_Quality_Flag',\n",
      "  '[2400x2400] //HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/Mandatory_Quality_Flag '\n",
      "  '(8-bit unsigned character)'),\n",
      " ('HDF5:\"VNP46A2.A2020214.h10v04.001.2021076005435.h5\"://HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/QF_Cloud_Mask',\n",
      "  '[2400x2400] //HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/QF_Cloud_Mask (16-bit '\n",
      "  'unsigned integer)'),\n",
      " ('HDF5:\"VNP46A2.A2020214.h10v04.001.2021076005435.h5\"://HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/Snow_Flag',\n",
      "  '[2400x2400] //HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/Snow_Flag (8-bit '\n",
      "  'unsigned character)')]\n"
     ]
    }
   ],
   "source": [
    "## Look at the subdatasets of your hdf file\n",
    "# you can also look at the documentation of your product to see this information\n",
    "hdffile = gdal.Open(rasterFiles[0], gdal.GA_ReadOnly)\n",
    "pprint(hdffile.GetSubDatasets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a4943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save chosen subdatasets as tif\n",
    "# for every HDF5 file in the array\n",
    "for item in rasterFiles:\n",
    "\n",
    "    # to work with .hdf5 and .h5 files\n",
    "    rasterFilePre = re.sub(\"\\.hdf5|\\.h5\", \"\", item)\n",
    "    \n",
    "    ## Open HDF file\n",
    "    hdflayer = gdal.Open(item, gdal.GA_ReadOnly)\n",
    "    \n",
    "    ## Open raster layer\n",
    "    # hdflayer.GetSubDatasets()[0][0] - for first layer (ntl)\n",
    "    # hdflayer.GetSubDatasets()[2][0] - for third layer (gap-filled ntl) ...etc\n",
    "    # [hdflayer.GetSubDatasets()[0][0], hdflayer.GetSubDatasets()[2][0]] - for multiple layers\n",
    "    \"\"\n",
    "    subhdflayer = [hdflayer.GetSubDatasets()[0][0]]\n",
    "    \"\"\n",
    "    # for every layer create new tif file\n",
    "    for subItem in subhdflayer:\n",
    "        rlayer = gdal.Open(subItem, gdal.GA_ReadOnly)\n",
    "        outputName = re.search(\"Data_Fields/.+$\", subItem)\n",
    "        outputName = outputName.string[(outputName.start() + 12):]\n",
    "        outputNameNoSpace = outputName.strip().replace(\" \",\"_\").replace(\"/\",\"_\")\n",
    "        outputNameFinal = rasterFilePre + \"_\" + outputNameNoSpace + fileExtension\n",
    "        outputRaster = outputFolder + outputNameFinal\n",
    "        \n",
    "        #collect bounding box coordinates\n",
    "        HorizontalTileNumber = int(rlayer.GetMetadata_Dict()[\"HorizontalTileNumber\"])\n",
    "        VerticalTileNumber = int(rlayer.GetMetadata_Dict()[\"VerticalTileNumber\"])\n",
    "        \n",
    "        WestBoundCoord = (10*HorizontalTileNumber) - 180\n",
    "        NorthBoundCoord = 90-(10*VerticalTileNumber)\n",
    "        EastBoundCoord = WestBoundCoord + 10\n",
    "        SouthBoundCoord = NorthBoundCoord - 10\n",
    "        \n",
    "        translateOptionText = EPSG + \" -a_nodata 65535 \" + \" -a_ullr \" + str(WestBoundCoord) + \" \" + str(NorthBoundCoord) + \" \" + str(EastBoundCoord) + \" \" + str(SouthBoundCoord)\n",
    "        translateoptions = gdal.TranslateOptions(gdal.ParseCommandLine(translateOptionText))\n",
    "        gdal.Translate(outputRaster, rlayer, options=translateoptions)\n",
    "        \n",
    "        #Display image in QGIS (run it within QGIS python Console) - remove comment to display\n",
    "        #iface.addRasterLayer(outputRaster, outputNameFinal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
